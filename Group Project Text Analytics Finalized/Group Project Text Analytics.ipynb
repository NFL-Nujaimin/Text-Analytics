{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0cbe08d-1022-4131-9417-4fa308a9c6dd",
   "metadata": {},
   "source": [
    "# Extract Data From Google Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0aadfd6-64cb-44e8-8c9a-4350b9911715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews have been output into CSV files.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Define Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--headless\") \n",
    "\n",
    "# Setup Chrome service\n",
    "chrome_service = Service(ChromeDriverManager().install())\n",
    "\n",
    "# Initialize the driver\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "def scrape_google_reviews(url, restaurant_name, max_scrolls=1000):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Let the page load completely\n",
    "\n",
    "    SCROLL_PAUSE_TIME = 0.2\n",
    "\n",
    "    # Scroll through the reviews section to load all reviews\n",
    "    divSideBar = driver.find_element(By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n",
    "    scrolls = 0\n",
    "    while scrolls < max_scrolls:\n",
    "        divSideBar.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        divSideBar.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        scrolls += 1\n",
    "\n",
    "    # Click \"More\" buttons to expand reviews\n",
    "    try:\n",
    "        next_items = driver.find_elements(By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[9]')\n",
    "        for item in next_items:\n",
    "            buttons = item.find_elements(By.TAG_NAME, 'button')\n",
    "            for button in buttons:\n",
    "                if button.text == \"More\":\n",
    "                    button.click()\n",
    "                    time.sleep(0.5)\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking 'More' buttons: {e}\")\n",
    "\n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    review_elements = response.find_all('div', class_='jftiEf')\n",
    "\n",
    "    reviews = []\n",
    "    for element in review_elements:\n",
    "        author = element.find('div', class_='d4r55').text if element.find('div', class_='d4r55') else ''\n",
    "        review_text = element.find('span', class_='wiI7pd').text if element.find('span', class_='wiI7pd') else ''\n",
    "        rating = 0\n",
    "        rating_element = element.find('span', class_='kvMYJc')\n",
    "        if rating_element and 'aria-label' in rating_element.attrs:\n",
    "            stars = rating_element['aria-label']\n",
    "            rating = int(stars[0]) if stars else 0\n",
    "        reviews.append({\"Restaurant\": restaurant_name, \"Author\": author, \"Rating\": rating, \"Review\": review_text})\n",
    "\n",
    "    return pd.DataFrame(reviews)\n",
    "\n",
    "# List of restaurant review URLs\n",
    "restaurant_urls = [\n",
    "    (\"Mr Dakgalbi @ IOI City Mall\", \"https://www.google.com/maps/place/Mr.+Dakgalbi+@+IOI+City+Mall/@2.9695377,101.7117839,17z/data=!3m1!5s0x31cdca0c047a47ed:0x41f6f4dcfa725c11!4m8!3m7!1s0x31cdca0eaae5554f:0x2f178fd5a73381dc!8m2!3d2.9695377!4d101.7143642!9m1!1b1!16s%2Fg%2F11c2r09z9w?entry=ttu\"),\n",
    "    (\"Ombak Kitchen @ IOI City Mall\", \"https://www.google.com/maps/place/Ombak+Kitchen+IOI+City+Mall,+Putrajaya/@2.969361,101.7099821,17z/data=!3m1!5s0x31cdca0c047a47ed:0x41f6f4dcfa725c11!4m8!3m7!1s0x31cdcb214da9b545:0xfc788fd97b812b03!8m2!3d2.9693556!4d101.712557!9m1!1b1!16s%2Fg%2F11rhvvfh8x?entry=ttu\"),\n",
    "    (\"Nando's @ IOI City Mall\", \"https://www.google.com/maps/place/Nando's+IOI+City+Mall/@2.9695664,101.7107493,17z/data=!4m8!3m7!1s0x31cdca0c1ac2a0f1:0xcee5ecc7ba0e8312!8m2!3d2.9695664!4d101.7133296!9m1!1b1!16s%2Fg%2F11btwttwr2?entry=ttu\"),\n",
    "    (\"KyoChon 1991 @ IOI City Mall\", \"https://www.google.com/maps/place/KyoChon+1991+@+IOI+City+Mall/@2.969697,101.7123299,17z/data=!3m1!5s0x31cdca0c047a47ed:0xaed1d10d9ef3a66f!4m8!3m7!1s0x31cdcba1a52ccea5:0x7da9990023eff55!8m2!3d2.969697!4d101.7149102!9m1!1b1!16s%2Fg%2F11h424z2y2?entry=ttu\"),\n",
    "    (\"The Manhattan Fish Market @ IOI City Mall\", \"https://www.google.com/maps/place/The+Manhattan+Fish+Market+@City+Mall+IOI/@2.9695853,101.7111811,17z/data=!4m8!3m7!1s0x31cdca0ea716881f:0x6d90d2ddfb9b1294!8m2!3d2.9695853!4d101.7137614!9m1!1b1!16s%2Fg%2F11b7t45sjg?entry=ttu\"),\n",
    "]\n",
    "\n",
    "# Extract reviews from URLs\n",
    "all_reviews = pd.DataFrame()\n",
    "\n",
    "for restaurant_name, url in restaurant_urls:\n",
    "    try:\n",
    "        reviews = scrape_google_reviews(url, restaurant_name)\n",
    "        all_reviews = pd.concat([all_reviews, reviews], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {restaurant_name}: {e}\")\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Save the reviews to a CSV file\n",
    "all_reviews.to_csv(\"restaurant_reviews.csv\", index=False)\n",
    "\n",
    "print(\"Reviews have been output into CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22f90f-ec05-434c-ac5f-c4ed5dc75d47",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6bea78-c6a8-49f1-af15-f7dfe5baa733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37fb3e13-0065-4a9f-bde9-1e2ddb96d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('restaurant_reviews.csv')\n",
    "\n",
    "# Drop rows where the review is null\n",
    "df = df.dropna(subset=['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48822eda-db1d-4380-8787-b203123ca403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KyoChon 1991 @ IOI City Mall: 620 reviews\n",
      "Ombak Kitchen @ IOI City Mall: 550 reviews\n",
      "Mr Dakgalbi @ IOI City Mall: 528 reviews\n",
      "Nando's @ IOI City Mall: 466 reviews\n",
      "The Manhattan Fish Market @ IOI City Mall: 413 reviews\n",
      "Preprocessed data has been saved to 'restaurant_reviews.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Perform text pre-processing\n",
    "stop_words = set(stopwords.words('english'))  # Create a set of English stopwords\n",
    "lemmatizer = WordNetLemmatizer()  # Initialize a WordNet lemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize the text into words and convert to lowercase\n",
    "    tokens = [token for token in tokens if token.isalnum()]  # Filter out non-alphanumeric tokens\n",
    "    tokens = [token for token in tokens if token not in stop_words]  # Remove stopwords from the tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatize each token\n",
    "    return ' '.join(tokens)  # Return the preprocessed tokens as a single string\n",
    "\n",
    "# Apply preprocessing to each review and add to a new column\n",
    "df['Processed Review'] = df['Review'].apply(preprocess_text)\n",
    "\n",
    "# Print out the total number of rows available for each restaurant\n",
    "restaurant_counts = df['Restaurant'].value_counts()\n",
    "for restaurant, count in restaurant_counts.items():\n",
    "    print(f\"{restaurant}: {count} reviews\")\n",
    "\n",
    "# Save the processed data to the same CSV file\n",
    "df.to_csv('restaurant_reviews.csv', index=False)\n",
    "\n",
    "print(\"Preprocessed data has been saved to 'restaurant_reviews.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91576f4c-91fd-4037-868b-ddd688ab5ea9",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Lexicon - Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91525f6d-494b-46a4-8b8a-a7744167f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2108615d-ba89-403f-92af-ad5c9fa36ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for TextBlob:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.65      0.69       465\n",
      "     neutral       0.05      0.05      0.05       175\n",
      "    positive       0.88      0.91      0.89      1937\n",
      "\n",
      "    accuracy                           0.80      2577\n",
      "   macro avg       0.56      0.54      0.55      2577\n",
      "weighted avg       0.80      0.80      0.80      2577\n",
      "\n",
      "Accuracy for TextBlob: 0.8040357004268529\n",
      "Evaluation for VADER:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.51      0.64       465\n",
      "     neutral       0.12      0.14      0.13       175\n",
      "    positive       0.86      0.93      0.89      1937\n",
      "\n",
      "    accuracy                           0.80      2577\n",
      "   macro avg       0.61      0.53      0.55      2577\n",
      "weighted avg       0.81      0.80      0.80      2577\n",
      "\n",
      "Accuracy for VADER: 0.8005432673651532\n",
      "Sentiment analysis results have been saved to 'restaurant_reviews.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze sentiment using TextBlob\n",
    "def analyze_sentiment_textblob(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "# Function to analyze sentiment using VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment_vader(text):\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    compound = score['compound']\n",
    "    if compound >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound > -0.05 and compound < 0.05:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "# Apply the sentiment analysis functions\n",
    "df['sentiment_textblob'] = df['Processed Review'].apply(analyze_sentiment_textblob)\n",
    "df['sentiment_vader'] = df['Processed Review'].apply(analyze_sentiment_vader)\n",
    "\n",
    "# Convert ratings to sentiment categories\n",
    "def score_to_sentiment(score):\n",
    "    if score >= 4:\n",
    "        return 'positive'\n",
    "    elif score == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "df['ActualSentiment'] = df['Rating'].apply(score_to_sentiment)\n",
    "\n",
    "# Evaluate the models\n",
    "print(\"Evaluation for TextBlob:\")\n",
    "print(classification_report(df['ActualSentiment'], df['sentiment_textblob']))\n",
    "print(\"Accuracy for TextBlob:\", accuracy_score(df['ActualSentiment'], df['sentiment_textblob']))\n",
    "\n",
    "print(\"Evaluation for VADER:\")\n",
    "print(classification_report(df['ActualSentiment'], df['sentiment_vader']))\n",
    "print(\"Accuracy for VADER:\", accuracy_score(df['ActualSentiment'], df['sentiment_vader']))\n",
    "\n",
    "# Save the processed data to the same CSV file\n",
    "df.to_csv('restaurant_reviews.csv', index=False)\n",
    "\n",
    "print(\"Sentiment analysis results have been saved to 'restaurant_reviews.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c4e57-3af5-4af9-bfcd-5caae626247f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
